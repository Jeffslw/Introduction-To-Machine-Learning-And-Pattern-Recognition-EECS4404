{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the original dataset\ndata = pd.read_csv('shuffled_redditinput.csv')\nX = data['text']\ny = data['emotion']\n\n# Preprocess the data using TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words='english')\nX_vectorized = vectorizer.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n\n# Train the Naive Bayes model\nnb_clf = MultinomialNB()\nnb_clf.fit(X_train, y_train)\n\n# Evaluate the model on the test set\ny_test_pred = nb_clf.predict(X_test)\naccuracy = accuracy_score(y_test, y_test_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification report:\\n\", classification_report(y_test, y_test_pred))\n\n# Load the new dataset\nnew_data = pd.read_csv('shuffled_tweetspredit.csv')\nX_new = new_data['text']\n\n# Preprocess the new text data using the same TfidfVectorizer\nX_new_vectorized = vectorizer.transform(X_new)\n\n# Make predictions on the new dataset\ny_new_pred = nb_clf.predict(X_new_vectorized)\n\n# Print the predicted emotions for the new dataset\nprint(\"Predicted emotions:\", y_new_pred)\n\n# Load the true labels (emotions) for the new dataset\ny_new_true = new_data['emotion']\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_new_true, y_new_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Generate a classification report\nreport = classification_report(y_new_true, y_new_pred)\nprint(\"Classification report:\\n\", report)",
      "metadata": {},
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 0.60\nClassification report:\n               precision    recall  f1-score   support\n\n       angry       0.54      0.74      0.63      1649\n     disgust       0.56      0.29      0.38      1044\n        fear       0.77      0.23      0.35       636\n       happy       0.62      0.84      0.71      1579\n         sad       0.59      0.63      0.61      1376\n    surprise       0.69      0.48      0.57      1084\n\n    accuracy                           0.60      7368\n   macro avg       0.63      0.54      0.54      7368\nweighted avg       0.61      0.60      0.57      7368\n\nPredicted emotions: ['happy' 'happy' 'angry' 'sad' 'sad' 'happy' 'angry' 'angry' 'happy'\n 'happy' 'surprise' 'disgust' 'happy' 'surprise' 'angry' 'disgust' 'angry'\n 'angry' 'angry' 'angry' 'angry' 'happy' 'happy' 'happy' 'happy' 'happy'\n 'sad' 'surprise' 'happy' 'sad' 'sad' 'angry' 'happy' 'happy' 'angry'\n 'sad' 'sad' 'happy' 'angry' 'happy' 'angry' 'happy' 'angry' 'sad' 'sad'\n 'angry' 'happy' 'surprise' 'angry' 'surprise' 'happy' 'surprise'\n 'disgust' 'sad' 'angry' 'happy' 'surprise' 'sad' 'happy' 'disgust'\n 'disgust' 'happy' 'happy' 'angry' 'disgust' 'sad' 'happy' 'angry'\n 'disgust' 'happy' 'angry' 'surprise' 'happy' 'happy' 'angry' 'happy'\n 'surprise' 'sad' 'angry' 'sad' 'happy' 'happy' 'disgust' 'happy' 'happy'\n 'angry' 'angry' 'happy' 'happy' 'sad' 'disgust' 'sad' 'sad' 'happy' 'sad'\n 'angry' 'angry' 'sad' 'angry' 'happy' 'surprise' 'sad' 'happy' 'surprise'\n 'happy' 'happy' 'happy' 'happy' 'sad' 'sad' 'sad' 'sad' 'angry' 'fear'\n 'angry' 'sad' 'angry' 'angry' 'happy' 'surprise' 'happy']\nAccuracy: 0.49\nClassification report:\n               precision    recall  f1-score   support\n\n       angry       0.32      0.50      0.39        20\n     disgust       0.89      0.40      0.55        20\n        fear       1.00      0.05      0.09        21\n       happy       0.42      0.90      0.57        20\n         sad       0.56      0.70      0.62        20\n    surprise       0.67      0.40      0.50        20\n\n    accuracy                           0.49       121\n   macro avg       0.64      0.49      0.45       121\nweighted avg       0.65      0.49      0.45       121\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}